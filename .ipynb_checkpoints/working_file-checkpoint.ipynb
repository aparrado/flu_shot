{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26707, 36)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pre-processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import tree\n",
    "from sklearn import linear_model\n",
    "\n",
    "# file names\n",
    "file_train = \"training_set_features.csv\"\n",
    "file_labels = \"training_set_labels.csv\"\n",
    "file_test = \"test_set_features.csv\"\n",
    "\n",
    "# datasets\n",
    "data_labels = pd.read_csv(file_labels)\n",
    "data_train = pd.read_csv(file_train)\n",
    "data_test = pd.read_csv(file_test)\n",
    "\n",
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    " ## Creating new column for variables that have more than 400 missing values\n",
    "numer_of_null = data_train.isnull().sum()\n",
    "names = list(numer_of_null.index)\n",
    "to_take_out = [] # it's name to_take_out, but I actually don't take out any variables\n",
    "\n",
    "## getting the names of all columns with more than 400 null values\n",
    "for element in names:\n",
    "    if numer_of_null[element] >=400:\n",
    "        to_take_out.append(element)\n",
    "        #print(\"Variable name:\",element)                 # useful just to get a sense of which variables\n",
    "        #print(\"Number of NA's\",numer_of_null[element])\n",
    "        \n",
    "# for these values, create new column showing that it is null        \n",
    "for element in to_take_out:\n",
    "    name_column = 'is_null_'+ element\n",
    "    data_train[name_column] = np.where(data_train[element].isnull(), 1, 0)   \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "respondent_id                  0\n",
       "h1n1_concern                   0\n",
       "h1n1_knowledge                 0\n",
       "behavioral_antiviral_meds      0\n",
       "behavioral_avoidance           0\n",
       "behavioral_face_mask           0\n",
       "behavioral_wash_hands          0\n",
       "behavioral_large_gatherings    0\n",
       "behavioral_outside_home        0\n",
       "behavioral_touch_face          0\n",
       "doctor_recc_h1n1               0\n",
       "doctor_recc_seasonal           0\n",
       "chronic_med_condition          0\n",
       "child_under_6_months           0\n",
       "health_worker                  0\n",
       "health_insurance               0\n",
       "opinion_h1n1_vacc_effective    0\n",
       "opinion_h1n1_risk              0\n",
       "opinion_h1n1_sick_from_vacc    0\n",
       "opinion_seas_vacc_effective    0\n",
       "opinion_seas_risk              0\n",
       "opinion_seas_sick_from_vacc    0\n",
       "age_group                      0\n",
       "education                      0\n",
       "race                           0\n",
       "sex                            0\n",
       "income_poverty                 0\n",
       "marital_status                 0\n",
       "rent_or_own                    0\n",
       "employment_status              0\n",
       "hhs_geo_region                 0\n",
       "census_msa                     0\n",
       "household_adults               0\n",
       "household_children             0\n",
       "employment_industry            0\n",
       "employment_occupation          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## setting up the imputer\n",
    "imp = SimpleImputer(missing_values = np.nan, strategy = 'most_frequent')\n",
    "\n",
    "## testing the imputer with training dataset\n",
    "var_names = list(data_train)\n",
    "imp.fit(data_train[var_names])\n",
    "data_train[var_names] = imp.transform(data_train[var_names])\n",
    "data_train = pd.DataFrame(data_train)\n",
    "\n",
    "\n",
    "## testing the imputer with test dataset\n",
    "var_names = list(data_test)\n",
    "imp.fit(data_test[var_names])\n",
    "data_test[var_names]= imp.transform(data_test[var_names])\n",
    "data_test = pd.DataFrame(data_test)\n",
    "\n",
    "## checking with variables have null values\n",
    "data_train.isnull().sum()\n",
    "data_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## on this chunk need to conver categorical variables into one-hot vectors\n",
    "\n",
    "cat_variables = ['age_group','education','race','income_poverty','marital_status',\n",
    "                'rent_or_own','employment_status','hhs_geo_region','census_msa',\n",
    "                 'household_children','employment_industry','employment_occupation','sex']\n",
    "\n",
    "\n",
    "data_train = pd.get_dummies(data_train, columns = cat_variables)\n",
    "data_test = pd.get_dummies(data_test, columns = cat_variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Female'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-f2d96e70789c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mY_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    802\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    525\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \"\"\"\n\u001b[0;32m--> 501\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Female'"
     ]
    }
   ],
   "source": [
    "## Training a tree classifier\n",
    "X_train = data_train\n",
    "Y_train = data_labels['h1n1_vaccine']\n",
    "X_test = data_test\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(min_samples_leaf=16)\n",
    "clf.fit(X_train, Y_train)\n",
    "Y_predicted = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    55 - 64 Years\n",
      "1    35 - 44 Years\n",
      "2    18 - 34 Years\n",
      "3        65+ Years\n",
      "4    45 - 54 Years\n",
      "Name: age_group, dtype: object\n",
      "0          < 12 Years\n",
      "1            12 Years\n",
      "2    College Graduate\n",
      "3            12 Years\n",
      "4        Some College\n",
      "Name: education, dtype: object\n",
      "0    White\n",
      "1    White\n",
      "2    White\n",
      "3    White\n",
      "4    White\n",
      "Name: race, dtype: object\n",
      "0                Below Poverty\n",
      "1                Below Poverty\n",
      "2    <= $75,000, Above Poverty\n",
      "3                Below Poverty\n",
      "4    <= $75,000, Above Poverty\n",
      "Name: income_poverty, dtype: object\n",
      "0    Not Married\n",
      "1    Not Married\n",
      "2    Not Married\n",
      "3    Not Married\n",
      "4        Married\n",
      "Name: marital_status, dtype: object\n",
      "0     Own\n",
      "1    Rent\n",
      "2     Own\n",
      "3    Rent\n",
      "4     Own\n",
      "Name: rent_or_own, dtype: object\n",
      "0    Not in Labor Force\n",
      "1              Employed\n",
      "2              Employed\n",
      "3    Not in Labor Force\n",
      "4              Employed\n",
      "Name: employment_status, dtype: object\n",
      "0    oxchjgsf\n",
      "1    bhuqouqj\n",
      "2    qufhixun\n",
      "3    lrircsnp\n",
      "4    qufhixun\n",
      "Name: hhs_geo_region, dtype: object\n",
      "0                     Non-MSA\n",
      "1    MSA, Not Principle  City\n",
      "2    MSA, Not Principle  City\n",
      "3         MSA, Principle City\n",
      "4    MSA, Not Principle  City\n",
      "Name: census_msa, dtype: object\n",
      "0    0.0\n",
      "1    0.0\n",
      "2    2.0\n",
      "3    0.0\n",
      "4    1.0\n",
      "Name: household_adults, dtype: float64\n",
      "0    0.0\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "Name: household_children, dtype: float64\n",
      "0         NaN\n",
      "1    pxcmvdjn\n",
      "2    rucpziij\n",
      "3         NaN\n",
      "4    wxleyezf\n",
      "Name: employment_industry, dtype: object\n",
      "0         NaN\n",
      "1    xgwztkwe\n",
      "2    xtkaffoo\n",
      "3         NaN\n",
      "4    emcorrxb\n",
      "Name: employment_occupation, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for var in cat_variables:\n",
    "    print(data_train[var].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>respondent_id</th>\n",
       "      <th>h1n1_concern</th>\n",
       "      <th>h1n1_knowledge</th>\n",
       "      <th>behavioral_antiviral_meds</th>\n",
       "      <th>behavioral_avoidance</th>\n",
       "      <th>behavioral_face_mask</th>\n",
       "      <th>behavioral_wash_hands</th>\n",
       "      <th>behavioral_large_gatherings</th>\n",
       "      <th>behavioral_outside_home</th>\n",
       "      <th>behavioral_touch_face</th>\n",
       "      <th>...</th>\n",
       "      <th>employment_occupation_qxajmpny</th>\n",
       "      <th>employment_occupation_rcertsgn</th>\n",
       "      <th>employment_occupation_tfqavkke</th>\n",
       "      <th>employment_occupation_ukymxvdu</th>\n",
       "      <th>employment_occupation_uqqtjvyb</th>\n",
       "      <th>employment_occupation_vlluhbov</th>\n",
       "      <th>employment_occupation_xgwztkwe</th>\n",
       "      <th>employment_occupation_xqwwgdyp</th>\n",
       "      <th>employment_occupation_xtkaffoo</th>\n",
       "      <th>employment_occupation_xzmlyyjv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 124 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   respondent_id  h1n1_concern  h1n1_knowledge  behavioral_antiviral_meds  \\\n",
       "0              0           1.0             0.0                        0.0   \n",
       "1              1           3.0             2.0                        0.0   \n",
       "2              2           1.0             1.0                        0.0   \n",
       "3              3           1.0             1.0                        0.0   \n",
       "4              4           2.0             1.0                        0.0   \n",
       "\n",
       "   behavioral_avoidance  behavioral_face_mask  behavioral_wash_hands  \\\n",
       "0                   0.0                   0.0                    0.0   \n",
       "1                   1.0                   0.0                    1.0   \n",
       "2                   1.0                   0.0                    0.0   \n",
       "3                   1.0                   0.0                    1.0   \n",
       "4                   1.0                   0.0                    1.0   \n",
       "\n",
       "   behavioral_large_gatherings  behavioral_outside_home  \\\n",
       "0                          0.0                      1.0   \n",
       "1                          0.0                      1.0   \n",
       "2                          0.0                      0.0   \n",
       "3                          1.0                      0.0   \n",
       "4                          1.0                      0.0   \n",
       "\n",
       "   behavioral_touch_face               ...                \\\n",
       "0                    1.0               ...                 \n",
       "1                    1.0               ...                 \n",
       "2                    0.0               ...                 \n",
       "3                    0.0               ...                 \n",
       "4                    1.0               ...                 \n",
       "\n",
       "   employment_occupation_qxajmpny  employment_occupation_rcertsgn  \\\n",
       "0                               0                               0   \n",
       "1                               0                               0   \n",
       "2                               0                               0   \n",
       "3                               0                               0   \n",
       "4                               0                               0   \n",
       "\n",
       "   employment_occupation_tfqavkke  employment_occupation_ukymxvdu  \\\n",
       "0                               0                               0   \n",
       "1                               0                               0   \n",
       "2                               0                               0   \n",
       "3                               0                               0   \n",
       "4                               0                               0   \n",
       "\n",
       "   employment_occupation_uqqtjvyb  employment_occupation_vlluhbov  \\\n",
       "0                               0                               0   \n",
       "1                               0                               0   \n",
       "2                               0                               0   \n",
       "3                               0                               0   \n",
       "4                               0                               0   \n",
       "\n",
       "   employment_occupation_xgwztkwe  employment_occupation_xqwwgdyp  \\\n",
       "0                               0                               0   \n",
       "1                               1                               0   \n",
       "2                               0                               0   \n",
       "3                               0                               0   \n",
       "4                               0                               0   \n",
       "\n",
       "   employment_occupation_xtkaffoo  employment_occupation_xzmlyyjv  \n",
       "0                               1                               0  \n",
       "1                               0                               0  \n",
       "2                               1                               0  \n",
       "3                               1                               0  \n",
       "4                               0                               0  \n",
       "\n",
       "[5 rows x 124 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
